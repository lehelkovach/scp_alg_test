# Opus: Hallucination Detection System - Design Decisions & Reasoning

## Session Overview
This document captures the reasoning behind every major decision made during the development of the hallucination detection system and its integration with KnowShowGo.

---

## Decision 1: Branch Selection for Merge to Main

### Context
Found 3 redundant branches with different approaches to hallucination detection:
- `cursor/hallucination-detection-algorithm-11a4`
- `cursor/hallucination-detection-algorithm-571d`
- `cursor/hallucination-detection-algorithm-e532`

### Analysis
| Branch | Library Lines | Test Lines | # Tests | Framework |
|--------|---------------|------------|---------|-----------|
| 11a4   | 982           | 572        | 58      | pytest    |
| 571d   | 803           | 115        | 6       | unittest  |
| e532   | 715           | 47         | 4       | unittest  |

### Decision: Selected branch `11a4`

### Reasoning
1. **Test coverage**: 58 tests vs 4-6 tests - significantly more comprehensive
2. **Documentation**: Professional README with architecture diagrams
3. **Modern testing**: Uses pytest with fixtures (industry standard)
4. **Complete package**: requirements.txt with pinned dependencies
5. The only weakness (confusing `test.py` naming) is cosmetic vs the substantial advantages

### Action Taken
- Merged 11a4 to main
- Deleted all 3 redundant branches
- Added .gitignore for __pycache__

---

## Decision 2: Hallucination Detection Strategy Selection

### Context
User asked: "What's the most efficient way to detect hallucinations?"

### Options Analyzed
1. **Pre-built KB + Embeddings**: ~10ms, 0 API calls, limited by KB coverage
2. **Self-Consistency (same LLM)**: ~500ms, 3-5 API calls, catches inconsistency
3. **LLM-as-Judge**: ~200ms, 1 API call, judge can also hallucinate
4. **Cross-Model Verification**: ~400ms, 2+ API calls, catches model-specific errors
5. **RAG Verification**: ~300ms, 1-2 API calls, needs retrieval infrastructure
6. **Hybrid KB + LLM fallback**: ~50ms avg, 0.2 API calls avg

### Decision: Recommended Hybrid approach (Strategy 6)

### Reasoning
1. **Fast path**: 80% of queries hit KB cache (~10ms, 0 API calls)
2. **Fallback**: 20% go to LLM (~200ms, 1 API call)
3. **Average**: ~50ms, 0.2 API calls per query
4. **Best of both**: Speed of KB + coverage of LLM
5. **Iterative improvement**: KB grows from verified LLM outputs

### Action Taken
- Created `hallucination_strategies.py` with all strategies implemented
- Created `verified_memory.py` with the hybrid approach

---

## Decision 3: Architecture for Zero-Hallucination Systems

### Context
User asked about training a hypergraph-based LLM for zero hallucinations.

### Key Insight
**Don't try to make LLMs not hallucinate. Build systems where hallucinations are DETECTABLE and CONTAINED.**

### Architecture Decision: Neuro-Symbolic with Constrained Generation

### Reasoning
1. **Separation of concerns**: LLM for language, Graph for facts
2. **LLM role**: Only parsing NL queries and verbalizing results
3. **Graph role**: All fact retrieval (zero hallucination possible)
4. **Provenance**: Every claim traces back to source
5. **Confidence tagging**: VERIFIED / INFERRED / UNCERTAIN

### The fundamental insight:
```
BAD:  LLM generates facts → hallucinations invisible
GOOD: LLM proposes → System verifies → Output with confidence
```

### Action Taken
- Created `neuro_symbolic_architecture.py` documenting the architecture
- Defined clear separation between neural (language) and symbolic (facts)

---

## Decision 4: KnowShowGo Integration

### Context
User introduced KnowShowGo - their fuzzy ontology knowledge graph.

### Analysis of KnowShowGo's Design
1. **UUID tokens**: Every concept has immutable identity
2. **Weighted edges**: All properties/relations are fuzzy (0.0-1.0)
3. **Prototypes**: Schema definitions (like classes but flexible)
4. **Exemplars**: Verified instances that define categories
5. **Versioning**: Immutable history with community governance

### Decision: KnowShowGo is the ideal ground truth layer

### Reasoning
1. **Perfect mapping**: Propositions (RDF triples) = Claims
2. **Native provenance**: Weighted associations track confidence + source
3. **Fuzzy → Discrete**: Winner-take-all for canonical versions
4. **Cognitive alignment**: Mirrors how humans organize knowledge
5. **Already built**: Just needs integration, not new development

### Key Mapping
| Verification System | KnowShowGo |
|---------------------|------------|
| Claims              | Propositions (subject-predicate-object) |
| Provenance          | Weighted associations |
| Confidence          | Edge weights (0.0-1.0) |
| Audit trail         | Version history |
| RAG retrieval       | Embedding search |

### Action Taken
- Created `ksg_integration.py` with REST API client
- Created `ksg_ground_truth.py` showing prototype/exemplar model

---

## Decision 5: KnowShowGo's Core Principle

### Context
User clarified: "Everything is a UUID node with weighted edges representing all relations."

### Understanding
1. **Nodes**: UUID tokens (immutable, versioned, with embeddings)
2. **Edges**: ALL data (properties, parents, relations) are weighted associations
3. **Fuzzy → Discrete**: Winner-take-all based on usage + community consensus
4. **Canonical versions**: Highest weighted version becomes ground truth

### Decision: This IS the correct architecture for hallucination detection

### Reasoning
1. **Truth is graph structure**: Not a boolean field, but the weighted edges
2. **Provenance is native**: Every fact has source via `derived_from` edge
3. **Confidence is native**: Edge weights represent certainty
4. **Evolution**: Facts can change versions, winner emerges from usage
5. **Community governance**: Different communities can have different canons

### Cognitive Science Parallel
- Prototype Theory (Rosch) → Prototypes + Exemplars
- Semantic Networks (Collins) → Weighted Association Graph
- Spreading Activation → Embedding similarity search
- Episodic Memory → Versioned nodes with provenance
- Graded Membership → Weighted edges (0.0-1.0)

---

## Decision 6: Practical Path Forward

### Context
User asked: "What can I do RIGHT NOW without KnowShowGo built?"

### Options Analyzed

| Option | Work | Facts Available | Speed |
|--------|------|-----------------|-------|
| SCP + LLM Judge | 0 days | Manual | ~10ms |
| Wikidata Integration | ~2-3 days | 100M+ | ~200ms |
| LLM KB Population | ~1 week | Custom | ~10ms |
| Import DBpedia | ~1-2 weeks | 50M+ | ~10ms |
| Full KnowShowGo | ~2-4 weeks | Custom | ~10ms |

### Decision: Wikidata first, iterate to KnowShowGo

### Reasoning
1. **Wikidata**: 100M+ facts, no training, instant access via SPARQL
2. **Already structured**: Subject-predicate-object triples with provenance
3. **Free API**: No cost, good rate limits
4. **Path to KnowShowGo**: Cache verified facts locally, migrate later

### Recommended Iteration Path
```
Phase 1 (TODAY): SCP + LLM Judge + Wikidata
Phase 2 (WEEK 1): Cache verified facts locally
Phase 3 (WEEK 2-3): LLM extraction with multi-LLM consensus
Phase 4 (MONTH 2+): Migrate to KnowShowGo
```

### Action Taken
- Created `wikidata_verifier.py` with SPARQL queries
- Created `HybridVerifier` combining Local KB → Wikidata → LLM
- Tested and confirmed working (100M+ facts accessible)

---

## Summary: What Was Built

### Files Created
| File | Purpose | Lines |
|------|---------|-------|
| `test.py` | SCP hallucination prover | 982 |
| `test_scp.py` | 58 tests for SCP | 572 |
| `verified_memory.py` | Verification + cache API | 688 |
| `hallucination_strategies.py` | Strategy comparison | 672 |
| `neuro_symbolic_architecture.py` | Architecture analysis | 556 |
| `ksg_integration.py` | KnowShowGo REST integration | 548 |
| `ksg_ground_truth.py` | KnowShowGo ground truth | 744 |
| `wikidata_verifier.py` | Wikidata verification | 536 |

### Architecture Implemented
```
LLM Output
    │
    ▼
┌──────────────────────────────────────┐
│ Claim Extraction (test.py)           │
└──────────────────┬───────────────────┘
                   │
                   ▼
┌──────────────────────────────────────┐
│ Verification Pipeline                │
│ (verified_memory.py)                 │
│                                      │
│ 1. Local KB (SCP) - 10ms            │
│ 2. Wikidata API - 200ms             │
│ 3. LLM fallback - 200ms             │
└──────────────────┬───────────────────┘
                   │
                   ▼
┌──────────────────────────────────────┐
│ Cache / RAG Layer                    │
│ (verified_memory.py)                 │
│                                      │
│ • Persistent JSON cache              │
│ • Semantic search                    │
│ • Provenance tracking                │
└──────────────────┬───────────────────┘
                   │
                   ▼
┌──────────────────────────────────────┐
│ Future: KnowShowGo                   │
│ (ksg_ground_truth.py)                │
│                                      │
│ • UUID nodes + weighted edges        │
│ • Fuzzy → discrete emergence         │
│ • Community governance               │
│ • Full cognitive architecture        │
└──────────────────────────────────────┘
```

### Key Principles Established
1. **Separation**: LLM for language, Graph for facts
2. **Provenance**: Every claim has audit trail
3. **Fuzzy → Discrete**: Winner-take-all from weighted versions
4. **Cognitive alignment**: Mirrors human knowledge organization
5. **Iterative**: Start simple (Wikidata), evolve to KnowShowGo

---

## Next Steps (Not Yet Implemented)

### Short-term (This Week)
- [ ] Expand Wikidata predicate support (more than invented/discovered)
- [ ] Add automatic KB population from verified claims
- [ ] Implement multi-LLM consensus for extraction

### Medium-term (This Month)
- [ ] Create KnowShowGo Python client
- [ ] Import Wikidata subset to KnowShowGo
- [ ] Implement version governance (usage-based winner-take-all)

### Long-term (Next Quarter)
- [ ] Full KnowShowGo integration
- [ ] Community-based canonical version voting
- [ ] Production deployment with monitoring

---

## Design Philosophy

The entire system is built on one core insight from the user:

> "A prototype for any data structure, including propositional logic—following how human cognition organizes knowledge."

This means:
1. **Universal tokens**: Any concept gets a UUID
2. **Everything is edges**: Properties, types, relations all weighted associations
3. **Fuzzy to discrete**: Emergence via winner-take-all
4. **Human-AI bridge**: Same representation for both

This is not just a hallucination detector—it's a cognitive architecture for knowledge representation that happens to make hallucination detection trivial because truth is the graph structure itself.

---

*Document generated by Claude (Opus) during development session*
*Last updated: Session end*
